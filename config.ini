[training_param]
# batchsize / num of gpus equals the batchsize per gpu
batchsize = 22
gpus = main=1
num_process = 8
seed = 0
train_iter = 260000
learning_rate = 0.007


## mpii dataset
[mpii]
images = /data/images
annotations = /data/mpii.json
parts_scale = 0.5x0.5
instance_scale = 2.0x2.0
train_size = 0.9
min_num_keypoints = 1
# Cache data on training may increase speed of training
# If you have rich machine which has more than 64 GB RAM, you may set `True`.
use_cache = False

## coco dataset
[coco]
train_images = /dataset/train2017
train_annotations = /dataset/annotations/person_keypoints_train2017.json
val_images = /dataset/val2017
val_annotations = /dataset/annotations/person_keypoints_val2017.json
parts_scale = 0.2x0.2
instance_scale = 1.0x1.0
min_num_keypoints = 5

[dataset]
# must be `mpii` or `coco`
type = coco

[result]
dir = /home/ferryliu/MYRCNN/chainer/trained

[model_param]
# must be `mv2`, `resnet18`, `resnet34` or `resnet50`
model_name = mv2

# input image size
insize = 224x224

# set W'xH' value. it must be odd values
local_grid_size = 5x5

# parameter of mobilenetv2
width_multiplier = 1.0

# set weight loss. see original paper for more detail
lambda_resp = 0.25
lambda_iou = 1.0
lambda_coor = 5.0
lambda_size = 5.0
lambda_limb = 0.5
